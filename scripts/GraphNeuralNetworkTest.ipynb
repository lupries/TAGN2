{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GraphNeuralNetworkTest.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lupries/TAGN2/blob/master/scripts/GraphNeuralNetworkTest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOBo8GGE_IVZ",
        "colab_type": "text"
      },
      "source": [
        "## Install necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2jGw3DHHQge",
        "colab_type": "code",
        "outputId": "c063eb4f-0633-4e88-8d0a-d918cf328adc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install torch-scatter\n",
        "!pip install torch-sparse\n",
        "!pip install torch-cluster\n",
        "!pip install torch-geometric"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch-scatter\n",
            "  Downloading https://files.pythonhosted.org/packages/b8/c3/8bad887ffa55c86f120ef5ae252dc0e357b3bd956d9fbf45242bacc46290/torch_scatter-1.4.0.tar.gz\n",
            "Building wheels for collected packages: torch-scatter\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-scatter: filename=torch_scatter-1.4.0-cp36-cp36m-linux_x86_64.whl size=3170457 sha256=6f1d4254cf0f0e294233d1d13270a2e629ed0f5f8f73667fc838a77e53a3332a\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/00/c4/1637b4b3003f29092f4fe2ad4b40dd10906269c1ac2dc82941\n",
            "Successfully built torch-scatter\n",
            "Installing collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-1.4.0\n",
            "Collecting torch-sparse\n",
            "  Downloading https://files.pythonhosted.org/packages/08/4e/a268613fa6a92ffbc65b89e66fc8be5590801937185007f0f7bcb75ea21f/torch_sparse-0.4.3.tar.gz\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-sparse) (1.3.3)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy->torch-sparse) (1.17.4)\n",
            "Building wheels for collected packages: torch-sparse\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-sparse: filename=torch_sparse-0.4.3-cp36-cp36m-linux_x86_64.whl size=3966671 sha256=c0f30c4345da446045cccc58a17beb9f3e3fca13f4723bb724bb882323793ae2\n",
            "  Stored in directory: /root/.cache/pip/wheels/02/66/2b/befece01c2516f9fb3e7b4d150bb2b871221c73657c9cd7735\n",
            "Successfully built torch-sparse\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.4.3\n",
            "Collecting torch-cluster\n",
            "  Downloading https://files.pythonhosted.org/packages/c3/70/1d827d6fd1e03bb5ae84852dd0070c6574105c37e7b935284f6e990932db/torch_cluster-1.4.5.tar.gz\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-cluster) (1.3.3)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy->torch-cluster) (1.17.4)\n",
            "Building wheels for collected packages: torch-cluster\n",
            "  Building wheel for torch-cluster (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-cluster: filename=torch_cluster-1.4.5-cp36-cp36m-linux_x86_64.whl size=16232146 sha256=14d99e606111ee0276c4f8fc87951bcab87f39c2af0300506b23651dc0a5c34d\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/26/7e/a6d6a80eae5ca39b92bc77773f36cf433d5085de18014382b1\n",
            "Successfully built torch-cluster\n",
            "Installing collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.4.5\n",
            "Collecting torch-geometric\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/50/0a802f0bfa68058bf025d219ec6fbe806a5b891bba6702e28be7b83679fb/torch_geometric-1.3.2.tar.gz (126kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.17.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.3.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.21.0)\n",
            "Collecting plyfile\n",
            "  Downloading https://files.pythonhosted.org/packages/4c/15/434d1d96f9a41fea56cb3290718123d651c56c4b7e53f0249acaf1bf34b6/plyfile-0.7.1.tar.gz\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.25.3)\n",
            "Collecting rdflib\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/fe/630bacb652680f6d481b9febbb3e2c3869194a1a5fc3401a4a41195a2f8f/rdflib-4.2.2-py3-none-any.whl (344kB)\n",
            "\u001b[K     |████████████████████████████████| 348kB 39.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.8.0)\n",
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.4)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->torch-geometric) (4.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->torch-geometric) (0.14.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from rdflib->torch-geometric) (2.4.5)\n",
            "Collecting isodate\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->torch-geometric) (1.12.0)\n",
            "Building wheels for collected packages: torch-geometric, plyfile\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-1.3.2-cp36-none-any.whl size=203339 sha256=fb0dfced15e4dbdcdda1836543484ce79f5673085b3ced5da15dbdf2a15acdfa\n",
            "  Stored in directory: /root/.cache/pip/wheels/f7/75/0a/56a0fd58efac6d990782523e20e61c9307fc42c31564d40348\n",
            "  Building wheel for plyfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for plyfile: filename=plyfile-0.7.1-cp36-none-any.whl size=32827 sha256=164cce2e6b02272b3a108ada5b492e79a17fd4077c3b221a920f47601a2700a0\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/0d/bf/6d603d81b98604d2ecfd5e99d4ab7c9af664fd5285ab82bbb0\n",
            "Successfully built torch-geometric plyfile\n",
            "Installing collected packages: plyfile, isodate, rdflib, torch-geometric\n",
            "Successfully installed isodate-0.6.0 plyfile-0.7.1 rdflib-4.2.2 torch-geometric-1.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45ybPeEsb4C9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "8ca3e889-07f7-4a34-c6ab-facd67a79bf0"
      },
      "source": [
        "!git clone https://lupries:lupri1789@github.com/lupries/TAGN2.git"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects:  11% (1/9)\u001b[K\rremote: Counting objects:  22% (2/9)\u001b[K\rremote: Counting objects:  33% (3/9)\u001b[K\rremote: Counting objects:  44% (4/9)\u001b[K\rremote: Counting objects:  55% (5/9)\u001b[K\rremote: Counting objects:  66% (6/9)\u001b[K\rremote: Counting objects:  77% (7/9)\u001b[K\rremote: Counting objects:  88% (8/9)\u001b[K\rremote: Counting objects: 100% (9/9)\u001b[K\rremote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects:  50% (1/2)\u001b[K\rremote: Compressing objects: 100% (2/2)\u001b[K\rremote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 5 (delta 3), reused 5 (delta 3), pack-reused 0\n",
            "Unpacking objects:  20% (1/5)   \rUnpacking objects:  40% (2/5)   \rUnpacking objects:  60% (3/5)   \rUnpacking objects:  80% (4/5)   \rUnpacking objects: 100% (5/5)   \rUnpacking objects: 100% (5/5), done.\n",
            "From https://github.com/lupries/TAGN2\n",
            "   8d9b672..fc0ff3f  master     -> origin/master\n",
            "Updating 8d9b672..fc0ff3f\n",
            "error: Your local changes to the following files would be overwritten by merge:\n",
            "\tmodels/graphnet/AttentiveGraphNeuralNetwork.py\n",
            "Please commit your changes or stash them before you merge.\n",
            "Aborting\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n30elCi8diBm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from TAGN2.models.graphnet import AGNN"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjEVHPV-N2lU",
        "colab_type": "code",
        "outputId": "a06e4fda-8cc6-47dd-882e-aa7e22cf8a3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "# initialize Graph Network\n",
        "graph = AGNN(2, 5, 5)\n",
        "#graph.interAttention.W_c.weight.data = torch.eye(5)\n",
        "graph = graph.cuda()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/TAGN2/models/convgru/convgru.py:22: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.\n",
            "  init.orthogonal(self.reset_gate.weight)\n",
            "/content/TAGN2/models/convgru/convgru.py:23: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.\n",
            "  init.orthogonal(self.update_gate.weight)\n",
            "/content/TAGN2/models/convgru/convgru.py:24: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.\n",
            "  init.orthogonal(self.out_gate.weight)\n",
            "/content/TAGN2/models/convgru/convgru.py:25: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
            "  init.constant(self.reset_gate.bias, 0.)\n",
            "/content/TAGN2/models/convgru/convgru.py:26: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
            "  init.constant(self.update_gate.bias, 0.)\n",
            "/content/TAGN2/models/convgru/convgru.py:27: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
            "  init.constant(self.out_gate.bias, 0.)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FS7iKjxLO3KC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create sample data\n",
        "data = torch.ones(3,5,10,10).cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAvyKPyHO_IP",
        "colab_type": "code",
        "outputId": "52e31096-cf46-4d50-8c9f-29b328485673",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "print(\"data: \" + str(data.shape))\n",
        "output = graph(data)\n",
        "print(\"output: \" + str(output.shape))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data: torch.Size([3, 5, 10, 10])\n",
            "output: torch.Size([3, 5, 10, 10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvCfozvH-Hsj",
        "colab_type": "text"
      },
      "source": [
        "## Implementation of Attentive Graph Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOKVQSweHCjP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch_geometric.nn import MessagePassing\n",
        "from torch_geometric.utils import add_self_loops, degree\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juJEB3LAHHWW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AGNN(MessagePassing):\n",
        "    \"\"\"\n",
        "    Graph Neural Network with Attention Modules for Message Passing and Convolutional GRU for Node Update\n",
        "\n",
        "    as described in Zero-Shot Video Object Segmentation via Attentive Graph Neural Networks\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, loops, channels, size, edge_index=None):\n",
        "        super(AGNN, self).__init__(aggr='add')\n",
        "        self.loops = loops\n",
        "        if edge_index is None:\n",
        "          edge_index = create_fully_connected()\n",
        "        self.edge_index = edge_index\n",
        "        # Attention Modules\n",
        "        self.intraAttention = SelfAttention(channels)\n",
        "        self.interAttention = InterAttention(channels, channels)\n",
        "        self.gate           = GAP(channels, channels, size)\n",
        "        # Convolutional Gated Recurrent Unit\n",
        "        self.convGRU        = ConvGRU(channels, channels, 3, 1)\n",
        "        self.hidden         = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x has shape [N, W, H, C]\n",
        "\n",
        "        # Propagate messages\n",
        "        for itr in range(self.loops):\n",
        "            x = self.propagate(edge_index=self.edge_index, x=x)\n",
        "            print(\"hidden: \"+str(x.shape))\n",
        "        return x\n",
        "\n",
        "    def message(self, x_i, x_j, edge_index):\n",
        "        # x_j and x_j   have shape  [E, C, W, H]\n",
        "        # edge_index    has shape   [2, E]\n",
        "\n",
        "        mask_selfAtt = edge_index[0] == edge_index[1]\n",
        "        x_i_selfAtt, x_j_selfAtt    = x_i[mask_selfAtt], x_j[mask_selfAtt]\n",
        "        x_i_interAtt, x_j_interAtt  = x_i[mask_selfAtt==False], x_j[mask_selfAtt==False]\n",
        "        assert (x_i_selfAtt == x_j_selfAtt).all()\n",
        "        \n",
        "        msg = torch.zeros_like(x_i)\n",
        "        # Intra-Attention messages\n",
        "        msg[mask_selfAtt]         = self.intraAttention.forward(x_i_selfAtt)\n",
        "        # Inter-Attention messages\n",
        "        msg[mask_selfAtt==False]  = self.interAttention.forward(x_i_interAtt, x_j_interAtt)\n",
        "        # Gate\n",
        "        gate_multiplier = self.gate.forward(msg)[:,:,0,0]\n",
        "        msg = (gate_multiplier.T * msg.T).T\n",
        "\n",
        "        return msg\n",
        "\n",
        "    def update(self, aggr_out):\n",
        "        # aggr_out has shape [N, C, H, W]\n",
        "        self.hidden = self.convGRU.forward(aggr_out, self.hidden)\n",
        "        # Return new node embeddings.\n",
        "        return self.hidden[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BesP3hhaOjYm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_fully_connected(num_nodes=3):\n",
        "\n",
        "  \"\"\"\n",
        "  Returns assignement matrix for fully-connected graph including self-loops\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  first_row = torch.tensor([])\n",
        "  second_row = torch.tensor([])\n",
        "  for num in range(num_nodes):\n",
        "    first_row =  torch.cat([first_row,  torch.ones(1,num_nodes)*num],1)\n",
        "    second_row = torch.cat([second_row, torch.tensor(np.arange(num_nodes)).float()])\n",
        "  edge_index = torch.cat([first_row, second_row.view(-1,second_row.size()[0])])\n",
        "\n",
        "  return edge_index.long()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}