{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FullModelTest.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lupries/TAGN2/blob/master/scripts/FullModelTest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQsEveoPtmJ8",
        "colab_type": "code",
        "outputId": "dec2c3fe-5e61-4926-8b9a-f78177569f59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "!git clone https://github.com/lupries/TAGN2.git\n",
        "!cd TAGN2 && git pull"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'TAGN2'...\n",
            "remote: Enumerating objects: 224, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/224)\u001b[K\rremote: Counting objects:   1% (3/224)\u001b[K\rremote: Counting objects:   2% (5/224)\u001b[K\rremote: Counting objects:   3% (7/224)\u001b[K\rremote: Counting objects:   4% (9/224)\u001b[K\rremote: Counting objects:   5% (12/224)\u001b[K\rremote: Counting objects:   6% (14/224)\u001b[K\rremote: Counting objects:   7% (16/224)\u001b[K\rremote: Counting objects:   8% (18/224)\u001b[K\rremote: Counting objects:   9% (21/224)\u001b[K\rremote: Counting objects:  10% (23/224)\u001b[K\rremote: Counting objects:  11% (25/224)\u001b[K\rremote: Counting objects:  12% (27/224)\u001b[K\rremote: Counting objects:  13% (30/224)\u001b[K\rremote: Counting objects:  14% (32/224)\u001b[K\rremote: Counting objects:  15% (34/224)\u001b[K\rremote: Counting objects:  16% (36/224)\u001b[K\rremote: Counting objects:  17% (39/224)\u001b[K\rremote: Counting objects:  18% (41/224)\u001b[K\rremote: Counting objects:  19% (43/224)\u001b[K\rremote: Counting objects:  20% (45/224)\u001b[K\rremote: Counting objects:  21% (48/224)\u001b[K\rremote: Counting objects:  22% (50/224)\u001b[K\rremote: Counting objects:  23% (52/224)\u001b[K\rremote: Counting objects:  24% (54/224)\u001b[K\rremote: Counting objects:  25% (56/224)\u001b[K\rremote: Counting objects:  26% (59/224)\u001b[K\rremote: Counting objects:  27% (61/224)\u001b[K\rremote: Counting objects:  28% (63/224)\u001b[K\rremote: Counting objects:  29% (65/224)\u001b[K\rremote: Counting objects:  30% (68/224)\u001b[K\rremote: Counting objects:  31% (70/224)\u001b[K\rremote: Counting objects:  32% (72/224)\u001b[K\rremote: Counting objects:  33% (74/224)\u001b[K\rremote: Counting objects:  34% (77/224)\u001b[K\rremote: Counting objects:  35% (79/224)\u001b[K\rremote: Counting objects:  36% (81/224)\u001b[K\rremote: Counting objects:  37% (83/224)\u001b[K\rremote: Counting objects:  38% (86/224)\u001b[K\rremote: Counting objects:  39% (88/224)\u001b[K\rremote: Counting objects:  40% (90/224)\u001b[K\rremote: Counting objects:  41% (92/224)\u001b[K\rremote: Counting objects:  42% (95/224)\u001b[K\rremote: Counting objects:  43% (97/224)\u001b[K\rremote: Counting objects:  44% (99/224)\u001b[K\rremote: Counting objects:  45% (101/224)\u001b[K\rremote: Counting objects:  46% (104/224)\u001b[K\rremote: Counting objects:  47% (106/224)\u001b[K\rremote: Counting objects:  48% (108/224)\u001b[K\rremote: Counting objects:  49% (110/224)\u001b[K\rremote: Counting objects:  50% (112/224)\u001b[K\rremote: Counting objects:  51% (115/224)\u001b[K\rremote: Counting objects:  52% (117/224)\u001b[K\rremote: Counting objects:  53% (119/224)\u001b[K\rremote: Counting objects:  54% (121/224)\u001b[K\rremote: Counting objects:  55% (124/224)\u001b[K\rremote: Counting objects:  56% (126/224)\u001b[K\rremote: Counting objects:  57% (128/224)\u001b[K\rremote: Counting objects:  58% (130/224)\u001b[K\rremote: Counting objects:  59% (133/224)\u001b[K\rremote: Counting objects:  60% (135/224)\u001b[K\rremote: Counting objects:  61% (137/224)\u001b[K\rremote: Counting objects:  62% (139/224)\u001b[K\rremote: Counting objects:  63% (142/224)\u001b[K\rremote: Counting objects:  64% (144/224)\u001b[K\rremote: Counting objects:  65% (146/224)\u001b[K\rremote: Counting objects:  66% (148/224)\u001b[K\rremote: Counting objects:  67% (151/224)\u001b[K\rremote: Counting objects:  68% (153/224)\u001b[K\rremote: Counting objects:  69% (155/224)\u001b[K\rremote: Counting objects:  70% (157/224)\u001b[K\rremote: Counting objects:  71% (160/224)\u001b[K\rremote: Counting objects:  72% (162/224)\u001b[K\rremote: Counting objects:  73% (164/224)\u001b[K\rremote: Counting objects:  74% (166/224)\u001b[K\rremote: Counting objects:  75% (168/224)\u001b[K\rremote: Counting objects:  76% (171/224)\u001b[K\rremote: Counting objects:  77% (173/224)\u001b[K\rremote: Counting objects:  78% (175/224)\u001b[K\rremote: Counting objects:  79% (177/224)\u001b[K\rremote: Counting objects:  80% (180/224)\u001b[K\rremote: Counting objects:  81% (182/224)\u001b[K\rremote: Counting objects:  82% (184/224)\u001b[K\rremote: Counting objects:  83% (186/224)\u001b[K\rremote: Counting objects:  84% (189/224)\u001b[K\rremote: Counting objects:  85% (191/224)\u001b[K\rremote: Counting objects:  86% (193/224)\u001b[K\rremote: Counting objects:  87% (195/224)\u001b[K\rremote: Counting objects:  88% (198/224)\u001b[K\rremote: Counting objects:  89% (200/224)\u001b[K\rremote: Counting objects:  90% (202/224)\u001b[K\rremote: Counting objects:  91% (204/224)\u001b[K\rremote: Counting objects:  92% (207/224)\u001b[K\rremote: Counting objects:  93% (209/224)\u001b[K\rremote: Counting objects:  94% (211/224)\u001b[K\rremote: Counting objects:  95% (213/224)\u001b[K\rremote: Counting objects:  96% (216/224)\u001b[K\rremote: Counting objects:  97% (218/224)\u001b[K\rremote: Counting objects:  98% (220/224)\u001b[K\rremote: Counting objects:  99% (222/224)\u001b[K\rremote: Counting objects: 100% (224/224)\u001b[K\rremote: Counting objects: 100% (224/224), done.\u001b[K\n",
            "remote: Compressing objects: 100% (172/172), done.\u001b[K\n",
            "remote: Total 224 (delta 87), reused 137 (delta 29), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (224/224), 8.67 MiB | 12.13 MiB/s, done.\n",
            "Resolving deltas: 100% (87/87), done.\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPnJQ9bft7AX",
        "colab_type": "code",
        "outputId": "c382d3a0-63dc-4e3a-8b69-d1c5c00ebadb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install torch-scatter\n",
        "!pip install torch-sparse\n",
        "!pip install torch-cluster\n",
        "!pip install torch-geometric"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch-scatter\n",
            "  Downloading https://files.pythonhosted.org/packages/b8/c3/8bad887ffa55c86f120ef5ae252dc0e357b3bd956d9fbf45242bacc46290/torch_scatter-1.4.0.tar.gz\n",
            "Building wheels for collected packages: torch-scatter\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-scatter: filename=torch_scatter-1.4.0-cp36-cp36m-linux_x86_64.whl size=3170365 sha256=8a49b014ad0f42109d49d3a6050ec3ec8be3f70ca424d2e6ad162b3b0f56d3f1\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/00/c4/1637b4b3003f29092f4fe2ad4b40dd10906269c1ac2dc82941\n",
            "Successfully built torch-scatter\n",
            "Installing collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-1.4.0\n",
            "Collecting torch-sparse\n",
            "  Downloading https://files.pythonhosted.org/packages/08/4e/a268613fa6a92ffbc65b89e66fc8be5590801937185007f0f7bcb75ea21f/torch_sparse-0.4.3.tar.gz\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-sparse) (1.3.3)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy->torch-sparse) (1.17.4)\n",
            "Building wheels for collected packages: torch-sparse\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-sparse: filename=torch_sparse-0.4.3-cp36-cp36m-linux_x86_64.whl size=3966625 sha256=3da4724d1c98208f7f44d21c02f1a94b7a77e5e416f4f77ab9f094ab1b02d423\n",
            "  Stored in directory: /root/.cache/pip/wheels/02/66/2b/befece01c2516f9fb3e7b4d150bb2b871221c73657c9cd7735\n",
            "Successfully built torch-sparse\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.4.3\n",
            "Collecting torch-cluster\n",
            "  Downloading https://files.pythonhosted.org/packages/c3/70/1d827d6fd1e03bb5ae84852dd0070c6574105c37e7b935284f6e990932db/torch_cluster-1.4.5.tar.gz\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-cluster) (1.3.3)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy->torch-cluster) (1.17.4)\n",
            "Building wheels for collected packages: torch-cluster\n",
            "  Building wheel for torch-cluster (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-cluster: filename=torch_cluster-1.4.5-cp36-cp36m-linux_x86_64.whl size=16231819 sha256=addf11d636629caf875536123a0c48a0119f5a093f45de89e09f3690df4a4e1c\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/26/7e/a6d6a80eae5ca39b92bc77773f36cf433d5085de18014382b1\n",
            "Successfully built torch-cluster\n",
            "Installing collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.4.5\n",
            "Collecting torch-geometric\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/50/0a802f0bfa68058bf025d219ec6fbe806a5b891bba6702e28be7b83679fb/torch_geometric-1.3.2.tar.gz (126kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 7.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.17.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.3.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.21.0)\n",
            "Collecting plyfile\n",
            "  Downloading https://files.pythonhosted.org/packages/4c/15/434d1d96f9a41fea56cb3290718123d651c56c4b7e53f0249acaf1bf34b6/plyfile-0.7.1.tar.gz\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.25.3)\n",
            "Collecting rdflib\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/fe/630bacb652680f6d481b9febbb3e2c3869194a1a5fc3401a4a41195a2f8f/rdflib-4.2.2-py3-none-any.whl (344kB)\n",
            "\u001b[K     |████████████████████████████████| 348kB 15.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.8.0)\n",
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.4)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->torch-geometric) (4.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->torch-geometric) (0.14.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (2.8)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from rdflib->torch-geometric) (2.4.5)\n",
            "Collecting isodate\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->torch-geometric) (1.12.0)\n",
            "Building wheels for collected packages: torch-geometric, plyfile\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-1.3.2-cp36-none-any.whl size=203339 sha256=6e7eacf15d36921141abc1e115a38be52c46c9d6c927cb6a11bacfca6ddd9a7c\n",
            "  Stored in directory: /root/.cache/pip/wheels/f7/75/0a/56a0fd58efac6d990782523e20e61c9307fc42c31564d40348\n",
            "  Building wheel for plyfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for plyfile: filename=plyfile-0.7.1-cp36-none-any.whl size=32827 sha256=1285bb1a21a3fef54819a31d73da84aa5713e4ceb96a3eb3cbdd1938398b743e\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/0d/bf/6d603d81b98604d2ecfd5e99d4ab7c9af664fd5285ab82bbb0\n",
            "Successfully built torch-geometric plyfile\n",
            "Installing collected packages: plyfile, isodate, rdflib, torch-geometric\n",
            "Successfully installed isodate-0.6.0 plyfile-0.7.1 rdflib-4.2.2 torch-geometric-1.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKkbdHA2pYsa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchfrom torch.nn import functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "from TAGN2.models.graphnet import AGNN\n",
        "from torchvision import models\n",
        "\n",
        "class TAGNN(nn.Module):\n",
        "\n",
        "    def __init__(self, loops):\n",
        "        super(TAGNN, self).__init__()\n",
        "\n",
        "        deeplab = models.segmentation.deeplabv3_resnet50(pretrained=False)\n",
        "        self.backbone = deeplab.backbone\n",
        "        self.graph = AGNN(loops=loops, channels=2048)\n",
        "        self.readout = models.segmentation.deeplabv3.DeepLabHead(2048, num_classes=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        input_shape = x.shape[-2:]\n",
        "        features = self.backbone(x)\n",
        "        x = features['out']\n",
        "        x = self.graph(x)\n",
        "        x = self.readout(x)\n",
        "\n",
        "        return F.interpolate(x, size=input_shape, mode='bilinear', align_corners=False)\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3Hz82h70ERq",
        "colab_type": "code",
        "outputId": "1cf6c19b-cd01-47c8-9667-5cd0595166da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = TAGNN(loops=2)\n",
        "model.cuda()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/TAGN2/models/convgru/convgru.py:22: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.\n",
            "  init.orthogonal(self.reset_gate.weight)\n",
            "/content/TAGN2/models/convgru/convgru.py:23: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.\n",
            "  init.orthogonal(self.update_gate.weight)\n",
            "/content/TAGN2/models/convgru/convgru.py:24: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.\n",
            "  init.orthogonal(self.out_gate.weight)\n",
            "/content/TAGN2/models/convgru/convgru.py:25: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
            "  init.constant(self.reset_gate.bias, 0.)\n",
            "/content/TAGN2/models/convgru/convgru.py:26: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
            "  init.constant(self.update_gate.bias, 0.)\n",
            "/content/TAGN2/models/convgru/convgru.py:27: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
            "  init.constant(self.out_gate.bias, 0.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TAGNN(\n",
              "  (backbone): IntermediateLayerGetter(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (4): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (5): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (graph): AGNN(\n",
              "    (intraAttention): SelfAttention(\n",
              "      (W_f): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (W_h): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (activation): Softmax(dim=-1)\n",
              "      (W_l): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "    (interAttention): InterAttention(\n",
              "      (W_c): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "      (activation): Softmax(dim=-1)\n",
              "    )\n",
              "    (gate): GAP(\n",
              "      (W_g): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (pooling): AdaptiveAvgPool2d(output_size=1)\n",
              "      (activation): Sigmoid()\n",
              "    )\n",
              "    (convGRU): ConvGRU(\n",
              "      (ConvGRUCell_00): ConvGRUCell(\n",
              "        (reset_gate): Conv2d(4096, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (update_gate): Conv2d(4096, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (out_gate): Conv2d(4096, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (readout): DeepLabHead(\n",
              "    (0): ASPP(\n",
              "      (convs): ModuleList(\n",
              "        (0): Sequential(\n",
              "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU()\n",
              "        )\n",
              "        (1): ASPPConv(\n",
              "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU()\n",
              "        )\n",
              "        (2): ASPPConv(\n",
              "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU()\n",
              "        )\n",
              "        (3): ASPPConv(\n",
              "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU()\n",
              "        )\n",
              "        (4): ASPPPooling(\n",
              "          (0): AdaptiveAvgPool2d(output_size=1)\n",
              "          (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (3): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (project): Sequential(\n",
              "        (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): Dropout(p=0.5, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): ReLU()\n",
              "    (4): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXGHfTAn0I-F",
        "colab_type": "code",
        "outputId": "7ba279ae-8eef-46d8-a97c-222b89a17ab5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "data = torch.ones(5,3,256,256).cuda()\n",
        "print(\"data: \" + str(data.shape))\n",
        "output = model(data)\n",
        "print(\"output: \" + str(output.shape))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data: torch.Size([5, 3, 256, 256])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "output: torch.Size([5, 1, 256, 256])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XR_X5gXnBQA2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
